{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# default_exp datapipe\n",
    "from nbdev import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datapipe - functions for data back-end / manipulations\n",
    "\n",
    "* This is the module for creating the data pipeline.\n",
    "* It should also be used to perform the data pre-processing and caching.\n",
    "\n",
    "* **NOTE: This is currently broken because the iCloud Drive has not downloaded the files as yet.**\n",
    "\n",
    "## Pre-process (prep) the data - do this ONCE and only ONCE - they put in some re-useable form\n",
    "\n",
    "0. Think about capturing walk metadata / do on a per-overall-walk basis \n",
    "1. Need to \"extract\" the data from the .fit files\n",
    "2. Clean/fix the data (e.g. allow for breaks in walk, change in order, not turning off walk at end)\n",
    "3. Concatenate into a single data-structure per overall walk \n",
    "4. Store in \"database\" e.g. sqlite, postgres?, files, or is Quilt sufficient?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#export\n",
    "import os\n",
    "import pandas as pd\n",
    "import activityio as aio\n",
    "from dateutil.parser import parse\n",
    "import datetime as dt\n",
    "import sqlite3 as sql\n",
    "from pathlib import Path\n",
    "import tomli\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "RAW_FIT_FILE_PATH = 'icloud/Data/HealthFit/FIT' \n",
    "WALK_DATABASE_NAME = 'emmaus_walking.db'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "fit_dir = Path.home()/RAW_FIT_FILE_PATH"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "db_file = Path(WALK_DATABASE_NAME)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "walks = []\n",
    "for path in sorted(fit_dir.iterdir()):\n",
    "        if path.is_dir():\n",
    "            walks.append([path.parts[-1], 'Name to be defined'])\n",
    "walks.append(['ALL', 'All Walks'])\n",
    "walks_df = pd.DataFrame(walks, columns=['walk_shortname', 'walk_name'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "walks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['B2M', 'Name to be defined'],\n",
       " ['B2W', 'Name to be defined'],\n",
       " ['D2C', 'Name to be defined'],\n",
       " ['GNW', 'Name to be defined'],\n",
       " ['GTL', 'Name to be defined'],\n",
       " ['GWW', 'Name to be defined'],\n",
       " ['OLD', 'Name to be defined'],\n",
       " ['SNM', 'Name to be defined'],\n",
       " ['STM', 'Name to be defined'],\n",
       " ['WNG', 'Name to be defined'],\n",
       " ['ALL', 'All Walks']]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "walks_df.to_json('walks_TBD.json', orient='table', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "[shortname + ': ' + name for shortname, name in pd.read_json('walks_TBD.json', orient='table').values.tolist()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B2M: Name to be defined',\n",
       " 'B2W: Name to be defined',\n",
       " 'D2C: Name to be defined',\n",
       " 'GNW: Name to be defined',\n",
       " 'GTL: Name to be defined',\n",
       " 'GWW: Name to be defined',\n",
       " 'OLD: Name to be defined',\n",
       " 'SNM: Name to be defined',\n",
       " 'STM: Name to be defined',\n",
       " 'WNG: Name to be defined',\n",
       " 'ALL: All Walks']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "WALK_DETAILS_FILE = 'walk_details.toml'\n",
    "walk_details = Path('../' + WALK_DETAILS_FILE)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "walk_details"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Path('../walk_details.toml')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "with open(walk_details, encoding=\"utf-8\") as f:\n",
    "    walk_details_dict = tomli.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "walk_details_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'walks': [{'short_name': 'B2M', 'name': 'Bondi to Manly'},\n",
       "  {'short_name': 'B2W', 'name': 'Bondi to Wollongong'},\n",
       "  {'short_name': 'D2C', 'name': 'Drummoyne to Cockatoo'},\n",
       "  {'short_name': 'GNW', 'name': 'Great North Walk'},\n",
       "  {'short_name': 'GTL', 'name': 'Gladesville Loop'},\n",
       "  {'short_name': 'GNW', 'name': 'Great North Walk'},\n",
       "  {'short_name': 'GWW', 'name': 'Great West Walk', 'status': 'incomplete'},\n",
       "  {'short_name': 'OLD', 'name': 'Old Bar'},\n",
       "  {'short_name': 'STM', 'name': \"St Michael's Golf Course\"},\n",
       "  {'short_name': 'SNM', 'name': 'Snowy Mountains (Thredo)'},\n",
       "  {'short_name': 'WNG',\n",
       "   'name': 'Newcastle to Sydney',\n",
       "   'status': 'incomplete'}]}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "pd.DataFrame(walk_details_dict, )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                walks\n",
       "0     {'short_name': 'B2M', 'name': 'Bondi to Manly'}\n",
       "1   {'short_name': 'B2W', 'name': 'Bondi to Wollon...\n",
       "2   {'short_name': 'D2C', 'name': 'Drummoyne to Co...\n",
       "3   {'short_name': 'GNW', 'name': 'Great North Walk'}\n",
       "4   {'short_name': 'GTL', 'name': 'Gladesville Loop'}\n",
       "5   {'short_name': 'GNW', 'name': 'Great North Walk'}\n",
       "6   {'short_name': 'GWW', 'name': 'Great West Walk...\n",
       "7            {'short_name': 'OLD', 'name': 'Old Bar'}\n",
       "8   {'short_name': 'STM', 'name': 'St Michael's Go...\n",
       "9   {'short_name': 'SNM', 'name': 'Snowy Mountains...\n",
       "10  {'short_name': 'WNG', 'name': 'Newcastle to Sy..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>walks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'short_name': 'B2M', 'name': 'Bondi to Manly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'short_name': 'B2W', 'name': 'Bondi to Wollon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'short_name': 'D2C', 'name': 'Drummoyne to Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'short_name': 'GNW', 'name': 'Great North Walk'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'short_name': 'GTL', 'name': 'Gladesville Loop'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'short_name': 'GNW', 'name': 'Great North Walk'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'short_name': 'GWW', 'name': 'Great West Walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'short_name': 'OLD', 'name': 'Old Bar'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'short_name': 'STM', 'name': 'St Michael's Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'short_name': 'SNM', 'name': 'Snowy Mountains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'short_name': 'WNG', 'name': 'Newcastle to Sy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def create_database_from_walk_files():\n",
    "\n",
    "    # Get proper paths for files/db sorted & keep backup of previous .db\n",
    "\n",
    "    fit_dir = Path.home()/RAW_FIT_FILE_PATH\n",
    "    db_file = Path('../' + WALK_DATABASE_NAME)\n",
    "    \n",
    "    if db_file.is_file():\n",
    "        print('Deleting existing database')\n",
    "        db_file.unlink()\n",
    "\n",
    "    db_conn = sql.connect(db_file)\n",
    "    print('Created: ' + db_file.resolve().as_posix())\n",
    "    \n",
    "    for path in fit_dir.iterdir():\n",
    "        if path.is_dir():\n",
    "            walk_name = path.parts[-1]\n",
    "            print(walk_name)\n",
    "            walk_data, walk_date, walk_files, points, walk_stats = load_and_cache_raw_walk_data(walk_name, 1, db_conn)\n",
    "\n",
    "            # create table of walk meta-data\n",
    "\n",
    "            walk_meta = pd.DataFrame([walk_name, walk_date, walk_stats])\n",
    "            try:\n",
    "                walk_meta.to_sql('walk_meta', db_conn, if_exists='append', index=False)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    db_conn.close()\n",
    "    return db_file, walk_meta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#export\n",
    "def calc_walk_stats(walk_data):\n",
    "    total_time = dt.timedelta(0)\n",
    "    total_distance = 0\n",
    "\n",
    "    for iHike, hike in enumerate(walk_data):\n",
    "        total_time += hike.index.max()\n",
    "        # print(iHike+1, walk_date[iHike], hike.index.max(), hike['dist'].max() / 1e3)\n",
    "        total_distance += hike['dist'].max()\n",
    "    total_distance /= 1e3\n",
    "\n",
    "    start_coord = walk_data[0][['lat', 'lon']].iloc[0].tolist()\n",
    "    end_coord = walk_data[-1][['lat', 'lon']].iloc[-1].tolist()\n",
    "    return total_time, total_distance, start_coord, end_coord\n",
    "\n",
    "\n",
    "# TODO: use st.cache() and also look to pre-load and cache/feather data (or similar) - NB: use of @st.cache() below didn't work\n",
    "def load_and_cache_raw_walk_data(walk_name, sample_freq, conn):\n",
    "    RAW_FIT_FILE_PATH = 'icloud/Data/HealthFit/FIT' \n",
    "    fit_dir = Path.home()/RAW_FIT_FILE_PATH\n",
    "    data_dir = fit_dir/walk_name[0:3]\n",
    "    #print(data_dir.ls())\n",
    "    data_files = [file for file in os.listdir(data_dir) if file.endswith('.fit')]\n",
    "    walk_files = sorted(data_files)\n",
    "    #print(walk_files)\n",
    "\n",
    "    walk_data = []\n",
    "    walk_date = []\n",
    "\n",
    "    for iFile, file in enumerate(walk_files):\n",
    "        #print(file)\n",
    "        #if Path(file).suffix == '.icloud':\n",
    "        #    print('Undownloaded files in iCloud Drive - STOP')\n",
    "        #    return False\n",
    "        walk_df = pd.DataFrame(aio.read(data_dir.joinpath(file)))\n",
    "        if len(walk_df) > 1:\n",
    "            walk_data.append(walk_df)\n",
    "            walk_date.append(parse(file[0:17]))\n",
    "            walk_df['WalkName'] = walk_name\n",
    "            walk_df['WalkNumber'] = iFile\n",
    "            walk_df[['alt', 'dist', 'lat', 'lon', 'speed', 'WalkName', 'WalkNumber']].to_sql('walks', conn, if_exists='append', index=False)\n",
    "               \n",
    "    total_time, total_distance, start_coord, end_coord = calc_walk_stats(walk_data)\n",
    "    walk_stats = [total_time, total_distance, start_coord, end_coord]\n",
    "    #print(start_coord)\n",
    "    walk_merged = pd.concat(walk_data)\n",
    "    points = walk_merged[['lat', 'lon']].values.tolist()\n",
    "    points = [tuple(point) for ipoint, point in enumerate(points) if ipoint % sample_freq == 0]\n",
    "    return walk_data, walk_date, walk_files, points, walk_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "db_file, walk_meta = create_database_from_walk_files()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleting existing database\n",
      "Created: /Users/mjboothaus/code/github/mjboothaus/emmaus_walking/emmaus_walking.db\n",
      "D2C\n",
      "GNW\n",
      "WNG\n",
      "OLD\n",
      "STM\n",
      "B2W\n",
      "B2M\n",
      "SNM\n",
      "GTL\n",
      "GWW\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "db_file"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Path('../emmaus_walking.db')"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def create_walk_datafile_for_app(db_file, n_rows_used=5):\n",
    "    # read in all of the walks data and sample at an appropriate frequency and cache for faster use in the app\n",
    "    db_conn = sql.connect(db_file)\n",
    "    walk_df = pd.read_sql_query('SELECT * FROM walks', db_conn)\n",
    "\n",
    "    UNUSED_COLUMNS = ['dist', 'speed']\n",
    "\n",
    "    walk_df.drop(UNUSED_COLUMNS, axis=1, inplace=True)\n",
    "    walk_df.dropna(inplace=True)      # TODO: Check why there are a few NaNs\n",
    "    walk_df = walk_df.iloc[::n_rows_used].reset_index()    # downsample\n",
    "\n",
    "    walk_df.to_csv(Path(db_file.as_posix().replace('.db', '.cache.csv')))\n",
    "    walk_df.to_excel(Path(db_file.as_posix().replace('.db', '.cache.xlsx')), index=False)\n",
    "    #walk_df.to_feather(Path(db_file.as_posix().replace('.db', '.cache.feather')))\n",
    "\n",
    "    #walk_df.to_pickle(Path(db_file.as_posix().replace('.db', '.cache.pickle')))\n",
    "    \n",
    "\n",
    "    # TODO: Consider using .parquet as the format - else just a SQLite database\n",
    "    return walk_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "walk_df = create_walk_datafile_for_app(db_file, 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "walk_df[walk_df['lat'].isna()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, alt, lat, lon, WalkName, WalkNumber]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>WalkName</th>\n",
       "      <th>WalkNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "Path(db_file.as_posix().replace('.db', '.cache.feather'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Path('../emmaus_walking.cache.feather')"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    walk_df = pd.read_feather(Path(db_file.as_posix().replace('.db', '.cache.feather')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "walk_df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "walk_df['WalkName'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('emmaus_walking_py38': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "a22d2645d3afe98160956a5bd9591f63a934537cdda62e90bef32e6cf34fead0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}